{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks project: Sentiment Analysis\n",
    "This a NLP (**Natural Language Processing**) learning project, of which task is to perform sentiment analysis on movie reviews. In this project we will be using an IMDB dataset containing 50,000 reviews classified as ***positive*** or ***negative***.\n",
    "\n",
    "The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k ***positive*** and 25k ***negative***). Also included are an additional 50,000 unlabeled documents for unsupervised learning.\n",
    "\n",
    "**Our intent in that project is to use different methods, i.e. different ANN models and different text encodings/embeddings, in the search of the best accuracy.**\n",
    "\n",
    "With regards to the ANN framework, we'll be using **PyTorch 1.5**.\n",
    "\n",
    "This dataset has been made publicly available by the authors of the following paper:\n",
    "\n",
    "***maas-EtAl:2011:ACL-HLT2011***\n",
    "* **author**    = Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher\n",
    "* **title**     = Learning Word Vectors for Sentiment Analysis\n",
    "* **booktitle** = Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies\n",
    "* **date**      = June 2011\n",
    "* **publisher** = Association for Computational Linguistics\n",
    "* **pages**     = 142--150\n",
    "* **url**       = http://www.aclweb.org/anthology/P11-1015\n",
    "\n",
    "Also, the **best performances** of ANNs on this dataset are listed [here](https://paperswithcode.com/sota/sentiment-analysis-on-imdb). The different methods are often listed with a companion paper giving great source of inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "A list of reference of the technologies used in this notebook.\n",
    "* (py)**Torch and Torchtext**: https://pytorch.org/\n",
    "* **spaCy**: https://spacy.io/\n",
    "* **GloVe**: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model: RNN, Encoding: one hot vectors\n",
    "For this first method, we are using a \"standard\" **Recurrent Neural Network** (RNN) and One Hot Encoding.\n",
    "\n",
    "**RNN** is a family of sequence based NNs, making them good for processing/understanding languages. We will use here the basic RNN.\n",
    "\n",
    "In **One Hot Encoding**, each word is encoded into a vector of 0 & 1. The dimension of each vector is the size of the vocabulary (i.e. if our corpus is made of 30,000 words, a word will be represented with a a vector of dimension 30,000).\n",
    "\n",
    "The drawbacks of such a representation is well known:\n",
    "* Sparse vector of high dimension. The bigger the vocabulary, the bigger the dimension of each vector, which makes the deep learning training intensively costly (in terms of time and resources), even unmanageable.\n",
    "* The encoding is totally uninformed, that is, similar words are not placed closer to each other in the encoding space.\n",
    "\n",
    "It is however a simple encoding method which is worth a try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Download and encode IMDB data\n",
    "We use TorchText as it provide easy access (download) to some popular dataset, including the IMDB dataset.\n",
    "\n",
    "First, we need to define our data Field and Label, we're using default PyTorch tokenisation for sequence (sentences), i.e. string.split (spliting a sequence simply on space).\n",
    "\n",
    "We will later improve the text processing/cleaning to verify the impact on the quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data.Field()\n",
    "labels = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**datasets.IMDB** will download (if not already present in ***.data*** directory) the IMDB Dataset and splits it into a train and test set. The data is processed using the **data.Field** settings defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.IMDB.splits(reviews, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 25000 training samples and 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has {0} training samples and {1} test samples\".format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of tokenised reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['If', 'there', 'is', 'one', 'thing', 'to', 'recommend', 'about', 'this', 'film', 'is', 'that', 'it', 'is', 'intriguing.', 'The', 'premise', 'certainly', 'draws', 'the', 'audience', 'in', 'because', 'it', 'is', 'a', 'mystery,', 'and', 'throughout', 'the', 'film', 'there', 'are', 'hints', 'that', 'there', 'is', 'something', 'dark', 'lurking', 'about.', 'However,', 'there', 'is', 'not', 'much', 'tension,', 'and', \"Williams'\", 'mild', 'mannered', 'portrayal', \"doesn't\", 'do', 'much', 'to', 'makes', 'us', 'relate', 'to', 'his', 'obsession', 'with', 'the', 'boy.<br', '/><br', '/>Collete', 'fares', 'much', 'better', 'as', 'the', 'woman', 'whose', 'true', 'nature', 'and', 'intentions', 'are', 'not', 'very', 'clear.', 'The', 'production', 'felt', 'rushed', 'and', 'holes', 'are', 'apparent.', 'It', 'certainly', 'feels', 'like', 'a', 'preview', 'for', 'a', 'much', 'more', 'complete', 'and', 'better', 'effort.', 'The', 'book', 'is', 'probably', 'better.<br', '/><br', '/>One', 'thing', 'is', 'certain:', 'Taupin', 'must', 'have', 'written', 'something', 'truly', 'good', 'to', 'have', 'inspired', 'at', 'least', 'one', 'commendable', 'effort.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data.examples[rd.randint(1,100)].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define a **validation set** (as 80% of the training data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_data.split(split_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the vocabulary of our corpus\n",
    "We set a limit, maximum size, of our vocabulary to keep the dimension of the one hot vectors manageable. Let's define a limit at **30,000 words** (tokens!).\n",
    "\n",
    "We only use the training set for building vocabulary. Indeed, we want to avoid introducing bias from validation/test data. That is, our model should be able to give a *sentiment* eventhough the review does **not** contain a word that our model have already learnt. Words not included into the vocabulary will be encoded as **<UNK>**, i.e. **UNKNOWN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_vocab_size = 30_000\n",
    "reviews.build_vocab(train_data, max_size=maximum_vocab_size)\n",
    "labels.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews **Field** can then show diverse information on the vocabulary, e.g.:\n",
    "\n",
    "* most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five most frequent words: [('the', 228701), ('a', 123678), ('and', 121873), ('of', 114229), ('to', 105933)]\n"
     ]
    }
   ],
   "source": [
    "print(\"The five most frequent words: {0}\".format(reviews.vocab.freqs.most_common(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Something to note here, is that the most frequent words are not necessarily those which could be of best used to identify a sentiment. There will be definitively something to improve here.***\n",
    "\n",
    "* the vocabulary (here, first 10 elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'I']\n"
     ]
    }
   ],
   "source": [
    "print(reviews.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ```<unk>``` and ```<pad>``` are not part of the initial vocabulary. They are tokens added for UNKNOWN vocabulary (*i.e. when limiting the size of the vocabulary, there are words that will not be included into the vocabulary, hence they will be tagged as UNKNOWN*) and for PADDING (*i.e. adding one or several PADDING token so that all sequences in a batch has the same length).\n",
    "\n",
    "As a result here, our vocabulary's size is **not 30,000 but 30,002**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to define an **iterator** that will be used for batch training. I.e. during training, our model will be fed with batch_size sequences. batch_size is one of the (many) deep learning hyper-parameters, and must be chosen wisely. Small batch size has been known to generalise better, although a batch size of 1 is also known to be a poor choice.\n",
    "\n",
    "Let's use 64.\n",
    "\n",
    "We also define the device (CPU or GPU) where to do all computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, validation_data, test_data),\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Build our simple RNN model\n",
    "Our RNN model will be comprised of:\n",
    "#### An embedding layer\n",
    "It transforms the sparse one hot vector into a denser vector. It is basically a linear layer to which one can feed indexes instead of vectors, i.e. a word/token is fed by the index of its one hot vector instead of by the one hot vector directly. Using embedding not only reduce the size of the dimension, but during training \"similar words\" (similarity being here depending on the task the embedding layer will be trained for) will be closer to each other.\n",
    "\n",
    "The layer takes as input dimension the size of the vocabulary. The output dimension is the desired dense vector dimension. The output dimension could be seen as an hyper-parameter and be tuned using cross-validation.\n",
    "\n",
    "***Note***: embedding layer can also be pre-trained, we'll use that later.\n",
    "#### An RNN layer\n",
    "The RNN layer takes as input dimension the embedding dimension (output of the embedding layer). The output dimension is the dimension of the hidden state. This dimension could also be seen as an hyperparameter of the model, i.e. could be tuned using cross-validation.\n",
    "#### A linear layer\n",
    "Our output layer is a classic linear (fully connected) layer. It takes into input the output of the RNN layer, and therefore the input dimension is the dimension of the RNN hidden state. The output dimension is one. Indeed, the problem here is a binary classification we can use a scalar within [0,1] bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, review):\n",
    "\n",
    "        embeddings = self.embedding(review)\n",
    "        output, hidden = self.rnn(embeddings)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        \n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting our model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(reviews.vocab)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of parameters of our model, which give insights of its complexity/simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN model has 3,873,409 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN model has {0:,} parameters\".format(model_parameters(model_rnn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the optimiser and the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(model_rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving computation to the appropriate device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = model_rnn.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Running the model\n",
    "We define here some helper functions to run and evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to compute accuracy**: the output of our last layer being an unbounded real, we first transform it to a real bounded to [0,1]. Values greater than 0.5 are then considered to be positive sentiment, whereas those less than 0.5 are considered to be negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    '''\n",
    "    accuracy of a batch of predictions.\n",
    "    Use sigmoid for transforming unbounded\n",
    "    predictions to [0,1]\n",
    "    Parameters\n",
    "    ----------\n",
    "    - predictions: a tensor of predictions\n",
    "    - labels: the correct labels for these predictions\n",
    "    Return\n",
    "    ------\n",
    "    - Accuracy = correct predictions / number of predictions\n",
    "    '''\n",
    "    predictions = torch.round(torch.sigmoid(predictions))\n",
    "    \n",
    "    # Correct prediction will be set to 1 from boolean True\n",
    "    # Allowing to compute accuracy\n",
    "    accuracy = (predictions == labels).float()\n",
    "    accuracy = accuracy.sum()/len(accuracy)\n",
    "    \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to train the model**: This function train the model for an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, optimiser, loss_fn):\n",
    "    '''\n",
    "    Train the model on a set of data (training set as batch)\n",
    "    That is, it performs the forward and backward propagation\n",
    "    steps as well as gradient descent for an epoch.\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the model to train\n",
    "    - the data: in iterator yielding batching of size\n",
    "        batch_size\n",
    "    - the chosen optimiser\n",
    "    - the chosen loss function\n",
    "    '''\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data_batch in data:\n",
    "        optimiser.zero_grad()\n",
    "        predictions = model(data_batch.text).squeeze(1)\n",
    "        loss = loss_fn(predictions, data_batch.label)\n",
    "        accuracy = get_accuracy(predictions, data_batch.label)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # accumulate loss and accuracy of each batch\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        epoch_accuracy = epoch_accuracy + accuracy.item()\n",
    "        \n",
    "    epoch_loss = epoch_loss / len(data)\n",
    "    epoch_accuracy = epoch_accuracy / len(data)\n",
    "    \n",
    "    return(epoch_loss, epoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to evaluate the model**: Evaluation -> we're using the validation set. Also, and **very important**, this is **NOT** training, so we do not compute the gradients. Apart from this, the function is quite similar to ***train_model()***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, loss_fn):\n",
    "    '''\n",
    "    Evaluate the model (-> using the validation set)\n",
    "    This is not training, i.e. we do not compute gradient\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the model to train\n",
    "    - the data: in iterator yielding batching of size\n",
    "        batch_size\n",
    "    - the chosen loss function\n",
    "    '''\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data_batch in data:\n",
    "            predictions = model(data_batch.text).squeeze(1)\n",
    "            loss = loss_fn(predictions, data_batch.label)\n",
    "            accuracy = get_accuracy(predictions, data_batch.label)\n",
    "        \n",
    "            # accumulate loss and accuracy of each batch\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "            epoch_accuracy = epoch_accuracy + accuracy.item()\n",
    "        \n",
    "    epoch_loss = epoch_loss / len(data)\n",
    "    epoch_accuracy = epoch_accuracy / len(data)\n",
    "    \n",
    "    return(epoch_loss, epoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to \"run\" the model**: loop through the number of epochs and run training and evaluation on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(nb_epochs, model, train_iter, valid_iter, optimiser, loss_fn):\n",
    "    '''\n",
    "    Run training, validation for all epochs\n",
    "    Output the loss and accuracy values for both\n",
    "    training and validation steps\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the number of epochs\n",
    "    - the model to train\n",
    "    - the train and validation data: (iterators)\n",
    "    - the chosen optimiser\n",
    "    - the chosen loss function\n",
    "    '''\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for an_epoch in range(nb_epochs):\n",
    "    \n",
    "        startt = datetime.now()\n",
    "    \n",
    "        train_loss, train_accuracy = train_model(model_rnn, train_iter, optimiser, loss_fn)\n",
    "        validation_loss, validation_accuracy = evaluate_model(model_rnn, valid_iter, loss_fn)\n",
    "    \n",
    "        duration = (datetime.now() - startt)\n",
    "        duration_str = \"{0}mn:{1}s\".format(duration.seconds//60, duration.seconds%60)\n",
    "    \n",
    "        print(\"epoch {0}: {1}\".format(an_epoch+1, duration_str))\n",
    "        print(\"\\t  Training loss: {0:.4f} |   Training accuracy: {1:.2f} %\".\n",
    "              format(train_loss, train_accuracy*100))\n",
    "        print(\"\\tValidation loss: {0:.4f} | Validation accuracy: {1:.2f} %\".\n",
    "              format(validation_loss, validation_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0mn:14s\n",
      "\t  Training loss: 0.6965 |   Training accuracy: 50.20 %\n",
      "\tValidation loss: 0.6959 | Validation accuracy: 49.94 %\n",
      "epoch 2: 0mn:14s\n",
      "\t  Training loss: 0.6939 |   Training accuracy: 50.79 %\n",
      "\tValidation loss: 0.6973 | Validation accuracy: 51.11 %\n",
      "epoch 3: 0mn:13s\n",
      "\t  Training loss: 0.6925 |   Training accuracy: 50.61 %\n",
      "\tValidation loss: 0.6991 | Validation accuracy: 51.46 %\n",
      "epoch 4: 0mn:13s\n",
      "\t  Training loss: 0.6921 |   Training accuracy: 50.22 %\n",
      "\tValidation loss: 0.7026 | Validation accuracy: 49.86 %\n",
      "epoch 5: 0mn:13s\n",
      "\t  Training loss: 0.6915 |   Training accuracy: 50.06 %\n",
      "\tValidation loss: 0.7052 | Validation accuracy: 52.22 %\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5\n",
    "run_model(nb_epochs, model_rnn, train_iter, valid_iter, optimiser, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Predicting sentiment on a review\n",
    "Let's pick up a review from test_data, i.e. reviews never seen byt our model and see how the model classify it. We're picking up a review at random, within the 25,000 reviews of the test set.\n",
    "\n",
    "But first let's define the function to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_sentiment_with_RNN(model, review_as_tokens):\n",
    "    '''\n",
    "    Predict the sentiment of a movie review\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the ANN model to use to predict\n",
    "    - A review as a list of tokens\n",
    "    Return\n",
    "    ------\n",
    "    A sentiment prediction, as a [0,1] real\n",
    "    A value < 0.5 meaning negative review\n",
    "    '''\n",
    "    model.eval()\n",
    "    review_indexed = [reviews.vocab.stoi[token] for token in review_as_tokens]\n",
    "    tensor = torch.LongTensor(review_indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    sentiment_prediction = torch.sigmoid(model(tensor))\n",
    "    return (sentiment_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now pick up at random a review amongst the 25000 reviews from the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'bought', 'this', 'film', 'from', 'e-bay', 'as', 'part', 'of', 'a', 'lot', 'of', 'about', 'twenty', 'horror', 'flicks,', 'all', 'about', 'a', 'dollar', 'a', 'piece.', 'When', 'watching', 'this,', 'my', 'first', 'impression', 'was', 'that', 'it', 'probably', 'was', 'from', 'the', 'late', '80s.', 'Later', 'on', 'I', 'began', 'thinking', '-', 'the', 'Linkin', 'Park', 'posters', 'on', 'the', 'wall', 'and', 'everything', 'else', 'seemed', 'to', 'hint', 'that', 'I', 'was', 'dealing', 'with', 'a', 'more', 'recent', 'film.', 'Realizing', 'that,', 'the', 'flick', 'became', 'an', 'unbearable', 'torment.', 'The', 'last', '3', 'minutes', 'were', 'the', 'longest', 'in', 'the', 'movie', 'history', '-', 'the', 'film', 'just', 'refused', 'to', 'end.', 'Is', 'there', 'a', 'genre', 'such', 'as', '\"horror', 'for', 'children\"?', 'In', 'that', 'case', 'this', 'film', 'is', 'definitely', 'it.', 'If', 'there', 'are', 'parents,', 'perverse', 'enough', 'to', 'want', 'to', 'introduce', 'their', 'offspring', 'to', 'horror,', 'I', 'suggest', 'this', 'would', 'be', 'perfect', 'for', 'kids', 'of', 'about', '6-8.', 'The', 'only', 'thing', 'I', 'really', 'liked', 'was', 'Greg', 'Cipes', 'who', 'was', 'much', 'too', 'good', 'an', 'actor', 'for', 'that', 'kind', 'of', 'nostalgic', 'retro', 'bottom', 'part', 'of', 'a', 'drive-in', 'double-bill.']\n",
      "\n",
      "This is a NEGATIVE review !\n"
     ]
    }
   ],
   "source": [
    "a_review = test_data.examples[rd.randint(1,25000)].__dict__\n",
    "a_review_label = a_review[\"label\"]\n",
    "a_review_text = a_review[\"text\"]\n",
    "print(\"{0}\\n\".format(a_review_text))\n",
    "if a_review_label == \"neg\":\n",
    "    print(\"This is a NEGATIVE review !\")\n",
    "else:\n",
    "    print(\"This is a POSITIVE review !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predict ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a POSITIVE review ! 0.5929\n"
     ]
    }
   ],
   "source": [
    "sentiment = predict_review_sentiment_with_RNN(model_rnn, a_review_text)\n",
    "if sentiment < 0.5:\n",
    "    print(\"This is a NEGATIVE review ! {0:.4f}\".format(sentiment))\n",
    "else:\n",
    "    print(\"This is a POSITIVE review ! {0:.4f}\".format(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make up our own review ... (*we're using spaCy here only for tokenisation of our review. We will discuss spaCy in the next section.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'such', 'a', 'bad', 'movie', '!']\n"
     ]
    }
   ],
   "source": [
    "#my_review = \"The best movie of the year\"\n",
    "#my_review = \"The best movie of the year. Very good, I like it, I enjoy it a lot. It's fun.\"\n",
    "my_review = \"This is such a bad movie!\"\n",
    "\n",
    "my_review_tokens = [token.text for token in nlp.tokenizer(my_review)]\n",
    "print(my_review_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the prediction of this review is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a NEGATIVE review ! 0.2163\n"
     ]
    }
   ],
   "source": [
    "sentiment = predict_review_sentiment_with_RNN(model_rnn, my_review_tokens)\n",
    "if sentiment < 0.5:\n",
    "    print(\"This is a NEGATIVE review ! {0:.4f}\".format(sentiment))\n",
    "else:\n",
    "    print(\"This is a POSITIVE review ! {0:.4f}\".format(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Conclusion on this RNN / One Hot Encoding model\n",
    "The accuracy of this model is pretty poor, basically equivallent to flipping a coin !\n",
    "\n",
    "Let's see if we can improve the accuracy with a better pre-processing of the text (reviews). In the next section, we will use **spaCy**, a powerful open source library for NLP, which includes many features (e.g. POS tagging, NER, etc.) and support many languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model: RNN, Text processing using spaCy\n",
    "We will be using the same ANN architecture (\"standard\" RNN), but we will use for tokenisation and removing ***stopwords***. Stopwords are usually the most common words in a language, e.g. \"**a**\", \"**the**\", \"**and**\", \"**of**\", etc., which may not bring a lot of benefit to a NLP task.\n",
    "\n",
    "**However**, negation words could be very important, typically in a sentiment analysis task.\n",
    "\n",
    "Let's see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two', 'almost', 'twelve', 'doing', 'here']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nlp.Defaults.stop_words)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Building and encoding the IMDB data\n",
    "We re-create our train, validation and test data using **spaCy**. This is done through parameters of the **Field** object. In the configuration below, we're using spaCy's tokeniser and spaCy's defined stop words.\n",
    "\n",
    "We're also adding some punctuation and specific stopwords in the spaCy default's stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words |= {\",\", \".\", \"-\", \";\", \":\", \"_\", \"/><br\", \"(\", \")\", \"!\", \"?\", \"...\", \"br\", \"/>\", \"'\", '\"'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews = data.Field(tokenize = \"spacy\")\n",
    "reviews = data.Field(tokenize = \"spacy\", stop_words = nlp.Defaults.stop_words)\n",
    "labels = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, test_data = datasets.IMDB.splits(reviews, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_data.split(split_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_vocab_size = 30_000\n",
    "reviews.build_vocab(train_data, max_size=maximum_vocab_size)\n",
    "labels.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five most frequent words: [('I', 62192), ('movie', 34141), ('film', 30974), ('The', 30223), ('like', 15535)]\n"
     ]
    }
   ],
   "source": [
    "print(\"The five most frequent words: {0}\".format(reviews.vocab.freqs.most_common(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'I', 'movie', 'film', 'The', 'like', 'It', 'good', 'This']\n"
     ]
    }
   ],
   "source": [
    "print(reviews.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***An improvement here compare to the previous encoding, as the most frequent words are not more punctuation***. Let see if it has an impact on the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, validation_data, test_data),\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Re-initalising the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(reviews.vocab)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimiser, loss and moving computation to the appropriate device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(model_rnn.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_rnn = model_rnn.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0mn:9s\n",
      "\t  Training loss: 0.6971 |   Training accuracy: 49.34 %\n",
      "\tValidation loss: 0.6990 | Validation accuracy: 49.33 %\n",
      "epoch 2: 0mn:9s\n",
      "\t  Training loss: 0.6947 |   Training accuracy: 50.43 %\n",
      "\tValidation loss: 0.7058 | Validation accuracy: 48.77 %\n",
      "epoch 3: 0mn:9s\n",
      "\t  Training loss: 0.6916 |   Training accuracy: 50.67 %\n",
      "\tValidation loss: 0.7193 | Validation accuracy: 50.79 %\n",
      "epoch 4: 0mn:9s\n",
      "\t  Training loss: 0.6914 |   Training accuracy: 50.65 %\n",
      "\tValidation loss: 0.7166 | Validation accuracy: 48.32 %\n",
      "epoch 5: 0mn:9s\n",
      "\t  Training loss: 0.6910 |   Training accuracy: 50.46 %\n",
      "\tValidation loss: 0.7241 | Validation accuracy: 51.34 %\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5\n",
    "run_model(nb_epochs, model_rnn, train_iter, valid_iter, optimiser, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Conclusion on this RNN / spaCy encoding model\n",
    "This model using **spaCy** tokeniser and **stopwords** shows no improvement compare to the previous one using \"standard\" pytorch tokeniser. If anything, the accuracy seems even a bit lower.\n",
    "\n",
    "We've also check there's no significant impact of the **stopwords** configuration, i.e. encoding our corpus with or without the stopwords option does not change significantly the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model: RNN, Pre-trained embeddings\n",
    "For this new model, we will again using the same ANN architecture (\"standard\" RNN). The change here is that we will be using pre-trained embeddings. Instead of building our embeddings **during** the training step, we will be using word embeddings that have been previously trained.\n",
    "\n",
    "**GloVe**, for Global Vectors for word representation, is an unsupervised learning algorithm for obtaining vector representations for words. In addition to the algorithm, some pre-trained words vectors (embeddings) are already available for download. The idea here is that, by having embeddings that have been extensively trained on many corpus, our model will be able to better identify sentiments from our IMDB review corpus, more partucularly on words that have not been seen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Building and encoding the IMDB data\n",
    "We re-create our train, validation and test data. We keep using **spaCy** for tokenisation, but do not use the **stopwords** feature. When building the vocabulary, we then specify to use the pre-trained embeddings from **GloVe**. That is, instead of having embedding layer being initialised randomly, we initialise it with the GloVe embeddings.\n",
    "\n",
    "There are different GloVe embeddings available, we will be using the **glove.6B.100d**. This particular embeddings is made up of **6 billions tokens**, a **vocabulary of 400,000** words, with each word being represented as a vector of **dimension 100**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data.Field(tokenize = \"spacy\")\n",
    "labels = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, test_data = datasets.IMDB.splits(reviews, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_data.split(split_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_vocab_size = 30_000\n",
    "reviews.build_vocab(train_data, max_size=maximum_vocab_size,\n",
    "                    vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "labels.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, validation_data, test_data),\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Re-initalising the model\n",
    "We change the embedding dimension to match the dimension of the GloVe embedding we're using (**dim=100**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(reviews.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the embedding layer with GloVe embeddings\n",
    "We replace the initial weights of the embedding layer (initialised during the instantiation of the RNN model in the above cell), with the GloVe embeddings weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6585, -0.8961,  2.6492,  ..., -0.4100,  0.5340,  0.6607],\n",
       "        [ 2.2799,  0.1549, -1.5530,  ..., -1.0601,  0.0717,  0.0137],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.7447, -0.2493, -0.0636,  ...,  0.1555,  1.0456,  0.1147],\n",
       "        [-0.5160,  0.0312,  0.0855,  ..., -0.8593,  0.0180,  0.7858],\n",
       "        [-0.2045,  0.0965, -0.4298,  ..., -0.4046,  0.4052,  0.3617]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GloVe_embeddings = reviews.vocab.vectors\n",
    "model_rnn.embedding.weight.data.copy_(GloVe_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also re-initialise the `<PAD>` and `<UNK>` weights to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.7447, -0.2493, -0.0636,  ...,  0.1555,  1.0456,  0.1147],\n",
       "        [-0.5160,  0.0312,  0.0855,  ..., -0.8593,  0.0180,  0.7858],\n",
       "        [-0.2045,  0.0965, -0.4298,  ..., -0.4046,  0.4052,  0.3617]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_idx = reviews.vocab.stoi[reviews.pad_token]\n",
    "unk_idx = reviews.vocab.stoi[reviews.unk_token]\n",
    "\n",
    "model_rnn.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "model_rnn.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model_rnn.embedding.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimiser, loss and moving computation to the appropriate device (GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(model_rnn.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_rnn = model_rnn.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Running the model\n",
    "We need to change our embedding dimension here, as the dimension of the GloVe embeddings we're using is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0mn:16s\n",
      "\t  Training loss: 0.6940 |   Training accuracy: 50.11 %\n",
      "\tValidation loss: 0.6946 | Validation accuracy: 50.10 %\n",
      "epoch 2: 0mn:16s\n",
      "\t  Training loss: 0.6931 |   Training accuracy: 50.08 %\n",
      "\tValidation loss: 0.7110 | Validation accuracy: 50.06 %\n",
      "epoch 3: 0mn:16s\n",
      "\t  Training loss: 0.6963 |   Training accuracy: 50.25 %\n",
      "\tValidation loss: 0.6961 | Validation accuracy: 49.76 %\n",
      "epoch 4: 0mn:15s\n",
      "\t  Training loss: 0.6955 |   Training accuracy: 49.82 %\n",
      "\tValidation loss: 0.6973 | Validation accuracy: 49.05 %\n",
      "epoch 5: 0mn:16s\n",
      "\t  Training loss: 0.6954 |   Training accuracy: 49.57 %\n",
      "\tValidation loss: 0.6937 | Validation accuracy: 49.58 %\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5\n",
    "run_model(nb_epochs, model_rnn, train_iter, valid_iter, optimiser, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Conclusion on this RNN / GloVe emmbedings model\n",
    "Perhaps surprisingly, using GloVe trained embeddings does not improve the accuracy of our model on the training and validation set. Possibly, the parameter that is likely limiting our accuracy is the model by itself. Keeping the vanilla RNN, we can still try different options, such as:\n",
    "* size of the hidden dimension\n",
    "* learning rate of the optimiser\n",
    "\n",
    "Before moving to a completely different ANN architecture, let's try doing a grid search over some hyperparameters of the mode, i.e. a combination of:\n",
    "* hidden_dim = [128, 256]\n",
    "* learning_rate = [0.01, 0.001, 00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [128, 256]\n",
    "learning_rates = [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with hidden_dim=128 and learning_rate=0.010000\n",
      "epoch 1: 0mn:16s\n",
      "\t  Training loss: 0.7115 |   Training accuracy: 49.55 %\n",
      "\tValidation loss: 0.7041 | Validation accuracy: 51.21 %\n",
      "epoch 2: 0mn:15s\n",
      "\t  Training loss: 0.7086 |   Training accuracy: 50.32 %\n",
      "\tValidation loss: 0.7424 | Validation accuracy: 50.36 %\n",
      "epoch 3: 0mn:17s\n",
      "\t  Training loss: 0.7135 |   Training accuracy: 50.37 %\n",
      "\tValidation loss: 0.7146 | Validation accuracy: 51.34 %\n",
      "---------\n",
      "Running model with hidden_dim=128 and learning_rate=0.001000\n",
      "epoch 1: 0mn:16s\n",
      "\t  Training loss: 0.6971 |   Training accuracy: 49.43 %\n",
      "\tValidation loss: 0.7104 | Validation accuracy: 48.38 %\n",
      "epoch 2: 0mn:16s\n",
      "\t  Training loss: 0.6948 |   Training accuracy: 50.45 %\n",
      "\tValidation loss: 0.7032 | Validation accuracy: 50.36 %\n",
      "epoch 3: 0mn:15s\n",
      "\t  Training loss: 0.6943 |   Training accuracy: 50.93 %\n",
      "\tValidation loss: 0.6991 | Validation accuracy: 49.86 %\n",
      "---------\n",
      "Running model with hidden_dim=128 and learning_rate=0.000100\n",
      "epoch 1: 0mn:15s\n",
      "\t  Training loss: 0.6943 |   Training accuracy: 49.89 %\n",
      "\tValidation loss: 0.6963 | Validation accuracy: 48.77 %\n",
      "epoch 2: 0mn:15s\n",
      "\t  Training loss: 0.6942 |   Training accuracy: 50.20 %\n",
      "\tValidation loss: 0.6961 | Validation accuracy: 51.05 %\n",
      "epoch 3: 0mn:15s\n",
      "\t  Training loss: 0.6937 |   Training accuracy: 50.65 %\n",
      "\tValidation loss: 0.6956 | Validation accuracy: 50.83 %\n",
      "---------\n",
      "Running model with hidden_dim=256 and learning_rate=0.010000\n",
      "epoch 1: 0mn:18s\n",
      "\t  Training loss: 0.7322 |   Training accuracy: 50.68 %\n",
      "\tValidation loss: 0.8312 | Validation accuracy: 49.11 %\n",
      "epoch 2: 0mn:18s\n",
      "\t  Training loss: 0.7116 |   Training accuracy: 49.90 %\n",
      "\tValidation loss: 0.6935 | Validation accuracy: 50.12 %\n",
      "epoch 3: 0mn:19s\n",
      "\t  Training loss: 0.7122 |   Training accuracy: 50.01 %\n",
      "\tValidation loss: 0.7298 | Validation accuracy: 48.95 %\n",
      "---------\n",
      "Running model with hidden_dim=256 and learning_rate=0.001000\n",
      "epoch 1: 0mn:18s\n",
      "\t  Training loss: 0.6988 |   Training accuracy: 49.97 %\n",
      "\tValidation loss: 0.7085 | Validation accuracy: 50.14 %\n",
      "epoch 2: 0mn:18s\n",
      "\t  Training loss: 0.6976 |   Training accuracy: 49.57 %\n",
      "\tValidation loss: 0.7004 | Validation accuracy: 49.25 %\n",
      "epoch 3: 0mn:18s\n",
      "\t  Training loss: 0.6977 |   Training accuracy: 50.29 %\n",
      "\tValidation loss: 0.6938 | Validation accuracy: 50.10 %\n",
      "---------\n",
      "Running model with hidden_dim=256 and learning_rate=0.000100\n",
      "epoch 1: 0mn:17s\n",
      "\t  Training loss: 0.6945 |   Training accuracy: 49.54 %\n",
      "\tValidation loss: 0.6976 | Validation accuracy: 49.70 %\n",
      "epoch 2: 0mn:18s\n",
      "\t  Training loss: 0.6941 |   Training accuracy: 50.21 %\n",
      "\tValidation loss: 0.6950 | Validation accuracy: 48.93 %\n",
      "epoch 3: 0mn:18s\n",
      "\t  Training loss: 0.6935 |   Training accuracy: 49.81 %\n",
      "\tValidation loss: 0.6945 | Validation accuracy: 50.77 %\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 3\n",
    "for hidden_dim, lr in product(hidden_dims, learning_rates):\n",
    "    \n",
    "    # change model settings\n",
    "    model_rnn = RNN(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "    model_rnn = model_rnn.to(device)\n",
    "    optimiser = optim.Adam(model_rnn.parameters(), lr=lr)\n",
    "    \n",
    "    print(\"Running model with hidden_dim={0} and learning_rate={1:.6f}\".\n",
    "          format(hidden_dim, lr))\n",
    "    \n",
    "    run_model(nb_epochs, model_rnn, train_iter, valid_iter, optimiser, loss_fn)\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5) Conclusion on grid search and general conclusion on this RNN model\n",
    "The grid search on the hyperparameters **(hidden dimension, learning rate)**, doesn't show any improvements in term of accuracy neither.\n",
    "It looks clear that, at least for this specific task of sentiment analysis, this particular, simple, RNN architecture is the limiting factor. Indeed, despite the different tunings and improvements we've tried on this model, we keep getting a poor accuracy, and loss not decreasing during training.\n",
    "\n",
    "In the next section we will build on what we've done so far (Spacy and GloVe embeddings) and try another architecture (**LSTM**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model: LSTM, Pre-trained embeddings\n",
    "Long Short-Term Memory (LSTM) networks are RNNs that  have been designed to overcome the main drawbacks of the standard RNNs:\n",
    "* standard RNNs have short-term memory. When a sequence is too long, RNNs struggle to propagate information from earlier steps to the later ones. That is definitively an issue with IMDB reviews, where reviews are multi-sentences.\n",
    "* standards RNNs suffer from vanishing (and exploding) gradient due to how backpropagation is performed (backpropagation through time).\n",
    "\n",
    "LSTMs have additional components' architecture that prevent these two drawbacks, in particular the memory cell C and the gates (update and forget gates) controlling the update of the memory cell.\n",
    "\n",
    "Another change we're introducing is ***packed padded sequences***. Instead of passing padded sequences (sequences with `<PAD>` tokens) to the LSTM, we'll pass the sequences without padding. We therefore need to tell the LSTM how long the sequences are. This can be returned by the torch.data.FIELD class when setting the parameters ***include_lengths***. This is what we will do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Building and encoding the IMDB data\n",
    "As previously, using **GloVe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data.Field(tokenize = \"spacy\", include_lengths = True)\n",
    "labels = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, test_data = datasets.IMDB.splits(reviews, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_data.split(split_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_vocab_size = 30_000\n",
    "reviews.build_vocab(train_data, max_size=maximum_vocab_size,\n",
    "                    vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
    "labels.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train_data, validation_data, test_data),\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               sort_within_batch=True,\n",
    "                                                               device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Build our LSTM model\n",
    "\n",
    "Our LSTM model will be comprised of:\n",
    "#### An embedding layer\n",
    "We'll use **GloVe** as previously as pre-trained embeddings. The layer takes as input dimension the size of the vocabulary. The output dimension must comply with the pre-trained embeddings used, i.e. here **100**.\n",
    "#### An LSTM layer\n",
    "The LSTM layer takes as input dimension the embedding dimension (output of the embedding layer). The output dimension is the dimension of the hidden state.\n",
    "#### A linear layer\n",
    "Our output layer is a classic linear (fully connected) layer. It takes into input the output of the LSTM layer, and therefore the input dimension is the dimension of the LSTM hidden state. The output dimension is one. Indeed, the problem here is a binary classification we can use a scalar within [0,1] bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim,\n",
    "                 output_dim, padding_idx):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, review, review_lengths):\n",
    "\n",
    "        embeddings = self.embedding(review)\n",
    "        \n",
    "        p_embeddings = nn.utils.rnn.pack_padded_sequence(embeddings, review_lengths)\n",
    "        p_output, (hidden, cell) = self.lstm(p_embeddings)\n",
    "        \n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(p_output)\n",
    "        hidden = self.fc(hidden[-1])\n",
    "        \n",
    "        return(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting our model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(reviews.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "padding_idx = reviews.vocab.stoi[reviews.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = LSTM(input_dim, embedding_dim, hidden_dim,\n",
    "                  output_dim, padding_idx)\n",
    "model_lstm = model_lstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN model has 3,367,049 parameters\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN model has {0:,} parameters\".format(model_parameters(model_lstm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the embedding layer with GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30002, 100])\n"
     ]
    }
   ],
   "source": [
    "GloVe_embeddings = reviews.vocab.vectors\n",
    "print(GloVe_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6106, -2.3774,  0.2805,  ..., -0.4891, -0.1276, -0.2461],\n",
       "        [ 1.0234, -0.3995, -0.7861,  ..., -0.1443, -0.6640, -0.7930],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.7447, -0.2493, -0.0636,  ...,  0.1555,  1.0456,  0.1147],\n",
       "        [-0.5160,  0.0312,  0.0855,  ..., -0.8593,  0.0180,  0.7858],\n",
       "        [-0.2045,  0.0965, -0.4298,  ..., -0.4046,  0.4052,  0.3617]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.embedding.weight.data.copy_(GloVe_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.7447, -0.2493, -0.0636,  ...,  0.1555,  1.0456,  0.1147],\n",
       "        [-0.5160,  0.0312,  0.0855,  ..., -0.8593,  0.0180,  0.7858],\n",
       "        [-0.2045,  0.0965, -0.4298,  ..., -0.4046,  0.4052,  0.3617]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_idx = reviews.vocab.stoi[reviews.unk_token]\n",
    "\n",
    "model_lstm.embedding.weight.data[padding_idx] = torch.zeros(embedding_dim)\n",
    "model_lstm.embedding.weight.data[unknown_idx] = torch.zeros(embedding_dim)\n",
    "model_lstm.embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(model_lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Running the model\n",
    "We need to redefine the train and evaluate function, as there's an additional parameter to take into account during training/validation (review lengths), due to our change to ***packed padded sequences***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(model, data, optimiser, loss_fn):\n",
    "    '''\n",
    "    Train the model on a set of data (training set as batch)\n",
    "    That is, it performs the forward and backward propagation\n",
    "    steps as well as gradient descent for an epoch.\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the model to train\n",
    "    - the data: in iterator yielding batching of size\n",
    "        batch_size\n",
    "    - the chosen optimiser\n",
    "    - the chosen loss function\n",
    "    '''\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data_batch in data:\n",
    "        optimiser.zero_grad()\n",
    "        review, review_lengths = data_batch.text\n",
    "        predictions = model(review, review_lengths).squeeze(1)\n",
    "        loss = loss_fn(predictions, data_batch.label)\n",
    "        accuracy = get_accuracy(predictions, data_batch.label)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        epoch_accuracy = epoch_accuracy + accuracy.item()\n",
    "    \n",
    "    epoch_loss = epoch_loss / len(data)\n",
    "    epoch_accuracy = epoch_accuracy / len(data)\n",
    "    \n",
    "    return(epoch_loss, epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(model, data, loss_fn):\n",
    "    '''\n",
    "    Evaluate the model (-> using the validation set)\n",
    "    This is not training, i.e. we do not compute gradient\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the model to train\n",
    "    - the data: in iterator yielding batching of size\n",
    "        batch_size\n",
    "    - the chosen loss function\n",
    "    '''\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data_batch in data:\n",
    "            review, review_lengths = data_batch.text\n",
    "            predictions = model(review, review_lengths).squeeze(1)\n",
    "            loss = loss_fn(predictions, data_batch.label)\n",
    "            accuracy = get_accuracy(predictions, data_batch.label)\n",
    "        \n",
    "            # accumulate loss and accuracy of each batch\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "            epoch_accuracy = epoch_accuracy + accuracy.item()\n",
    "        \n",
    "    epoch_loss = epoch_loss / len(data)\n",
    "    epoch_accuracy = epoch_accuracy / len(data)\n",
    "    \n",
    "    return(epoch_loss, epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_model(nb_epochs, model, train_iter, valid_iter, optimiser, loss_fn):\n",
    "    '''\n",
    "    Run training, validation for all epochs\n",
    "    Output the loss and accuracy values for both\n",
    "    training and validation steps\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the number of epochs\n",
    "    - the model to train\n",
    "    - the train and validation data: (iterators)\n",
    "    - the chosen optimiser\n",
    "    - the chosen loss function\n",
    "    '''\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for an_epoch in range(nb_epochs):\n",
    "    \n",
    "        startt = datetime.now()\n",
    "    \n",
    "        train_loss, train_accuracy = train_lstm_model(model_lstm, train_iter, optimiser, loss_fn)\n",
    "        validation_loss, validation_accuracy = evaluate_lstm_model(model_lstm, valid_iter, loss_fn)\n",
    "    \n",
    "        duration = (datetime.now() - startt)\n",
    "        duration_str = \"{0}mn:{1}s\".format(duration.seconds//60, duration.seconds%60)\n",
    "    \n",
    "        print(\"epoch {0}: {1}\".format(an_epoch+1, duration_str))\n",
    "        print(\"\\t  Training loss: {0:.4f} |   Training accuracy: {1:.2f} %\".\n",
    "              format(train_loss, train_accuracy*100))\n",
    "        print(\"\\tValidation loss: {0:.4f} | Validation accuracy: {1:.2f} %\".\n",
    "              format(validation_loss, validation_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0mn:16s\n",
      "\t  Training loss: 0.6380 |   Training accuracy: 63.04 %\n",
      "\tValidation loss: 0.5946 | Validation accuracy: 68.55 %\n",
      "epoch 2: 0mn:16s\n",
      "\t  Training loss: 0.4870 |   Training accuracy: 77.68 %\n",
      "\tValidation loss: 0.5528 | Validation accuracy: 72.05 %\n",
      "epoch 3: 0mn:16s\n",
      "\t  Training loss: 0.3658 |   Training accuracy: 84.43 %\n",
      "\tValidation loss: 0.3614 | Validation accuracy: 84.89 %\n",
      "epoch 4: 0mn:16s\n",
      "\t  Training loss: 0.2346 |   Training accuracy: 90.88 %\n",
      "\tValidation loss: 0.3268 | Validation accuracy: 87.38 %\n",
      "epoch 5: 0mn:16s\n",
      "\t  Training loss: 0.1689 |   Training accuracy: 93.80 %\n",
      "\tValidation loss: 0.4158 | Validation accuracy: 81.45 %\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5\n",
    "run_lstm_model(nb_epochs, model_lstm, train_iter, valid_iter, optimiser, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Predicting sentiment on a review\n",
    "Let's again use some test_data reviews and a made-up review as previously and see if this LSTM model is predicting better reviews that have never been seen.\n",
    "\n",
    "But first we need to change the predict function to include the length of our review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_sentiment_with_LSTM(model, review_as_tokens):\n",
    "    '''\n",
    "    Predict the sentiment of a movie review\n",
    "    Parameters\n",
    "    ----------\n",
    "    - the ANN model to use to predict\n",
    "    - A review as a list of tokens\n",
    "    Return\n",
    "    ------\n",
    "    A sentiment prediction, as a [0,1] real\n",
    "    A value < 0.5 meaning negative review\n",
    "    '''\n",
    "    model.eval()\n",
    "    review_indexed = [reviews.vocab.stoi[token] for token in review_as_tokens]\n",
    "    review_length = [len(review_indexed)]\n",
    "    review_tensor = torch.LongTensor(review_indexed).to(device)\n",
    "    review_tensor = review_tensor.unsqueeze(1)\n",
    "    review_length_as_tensor = torch.LongTensor(review_length)\n",
    "    sentiment_prediction = torch.sigmoid(model(review_tensor, review_length_as_tensor))\n",
    "    return (sentiment_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now pick up at random a review amongst the 25000 reviews from the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rainy', 'day', 'with', 'not', 'much', 'to', 'do', '.', 'We', 'were', 'surfing', 'the', 'movie', 'network', 'channels', 'and', 'found', 'this', 'one', 'just', 'starting', ',', 'so', 'we', 'gave', 'it', 'a', 'chance.<br', '/><br', '/>The', 'more', 'we', 'watched', ',', 'the', 'more', 'we', 'became', 'engrossed', 'in', 'the', 'story', '.', 'Its', 'the', 'old', 'story', 'of', 'working', 'class', 'underdog', 'trying', 'to', 'make', 'it', 'in', 'a', 'sport', 'which', 'at', 'the', 'time', '(', '1913', 'I', 'think', ')', 'was', 'usually', 'played', 'by', 'the', 'wealthy', 'upper', 'class', 'but', 'this', 'movie', 'was', 'every', 'bit', 'as', 'interesting', 'as', 'Seabiscuit', 'and', 'this', 'is', 'also', 'based', 'on', 'a', 'true', 'story.<br', '/><br', '/>The', 'acting', 'is', 'believable', 'and', 'the', 'casting', 'is', 'brilliant', '.', 'AND', '.', '.', '.', '.', 'we', 'are', 'NOT', 'golfers', ',', 'so', 'please', 'do', \"n't\", 'miss', 'this', 'one', 'just', 'because', 'its', 'about', 'golf', '.', 'Any', 'individual', 'sport', 'would', 'serve', 'the', 'plot', ',', 'because', 'it', \"'s\", 'about', 'the', 'people', '.', 'Golf', 'works', 'well', 'for', 'this', 'story', 'because', 'of', 'the', 'class', 'distinction', 'and', 'snobbery', 'that', 'seem', 'to', 'involve', 'some', 'who', 'play', 'the', 'game.<br', '/><br', '/>Bottom', 'line', '.', '.', '.', '.', 'Its', 'a', 'feel', 'good', 'movie', '.', 'It', \"'s\", 'well', 'put', 'together', 'and', 'is', \"n't\", 'it', 'always', 'fun', 'to', 'see', 'those', 'who', 'think', 'they', 'are', 'better', 'than', 'others', 'get', 'taken', 'down', 'a', 'peg', 'or', 'two', '.']\n",
      "\n",
      "This is a POSITIVE review !\n"
     ]
    }
   ],
   "source": [
    "a_review = test_data.examples[rd.randint(1,25000)].__dict__\n",
    "a_review_label = a_review[\"label\"]\n",
    "a_review_text = a_review[\"text\"]\n",
    "print(\"{0}\\n\".format(a_review_text))\n",
    "if a_review_label == \"neg\":\n",
    "    print(\"This is a NEGATIVE review !\")\n",
    "else:\n",
    "    print(\"This is a POSITIVE review !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predict ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a POSITIVE review ! 0.5116\n"
     ]
    }
   ],
   "source": [
    "sentiment = predict_review_sentiment_with_LSTM(model_lstm, a_review_text)\n",
    "if sentiment < 0.5:\n",
    "    print(\"This is a NEGATIVE review ! {0:.4f}\".format(sentiment))\n",
    "else:\n",
    "    print(\"This is a POSITIVE review ! {0:.4f}\".format(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make up our own review ... (*we're using spaCy here only for tokenisation of our review. We will discuss spaCy in the next section.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best', 'movie', 'of', 'the', 'year', '.', 'Very', 'good', ',', 'I', 'like', 'it', ',', 'I', 'enjoy', 'it', 'a', 'lot', '.', 'It', \"'s\", 'fun', '.']\n"
     ]
    }
   ],
   "source": [
    "#my_review = \"The best movie of the year\"\n",
    "my_review = \"The best movie of the year. Very good, I like it, I enjoy it a lot. It's fun.\"\n",
    "#my_review = \"This is such a bad movie!\"\n",
    "\n",
    "my_review_tokens = [token.text for token in nlp.tokenizer(my_review)]\n",
    "print(my_review_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the prediction of this review is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a POSITIVE review ! 0.9791\n"
     ]
    }
   ],
   "source": [
    "sentiment = predict_review_sentiment_with_LSTM(model_lstm, my_review_tokens)\n",
    "if sentiment < 0.5:\n",
    "    print(\"This is a NEGATIVE review ! {0:.4f}\".format(sentiment))\n",
    "else:\n",
    "    print(\"This is a POSITIVE review ! {0:.4f}\".format(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Conclusion on this LSTM / GloVe emmbedings model\n",
    "The results of this model are significantly better than all previous models! First of all we can see the loss getting smaller and smaller at each Epoch. And then, we managed to have an accuracy greater than **90%** on the training set!! That's a huge jump from the accuracy around 50% from all the other models.\n",
    "\n",
    "The LSTM is clearly a better model for this task of sentiment analysis. Given the structure of the data for our IMDB review sentiment analysis, it's very likely that the jump of performance is due to LSTM abilities to handle long sequences.\n",
    "\n",
    "However not everything is perfect here. We can observe quite a gap between the accuracy on the training set and on the validation set (for this particular run, more than 10 points on the last epoch, i.e. 93% of accuracy on the training dataset versus 81% on the validation dataset). This is a typical sign of our model **overfitting**. We can try to correct overfitting by using **regularisation**. One computationally cheap and effective way of doing regularisation for ANN is **dropout**. We'll add dropout to our LSTM model in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model: Adding Dropout to LSTM & Pre-trained embeddings\n",
    "We're here simply adding **dropout** to our previous **LSTM/GloVe** model. Dropout is simply the action of **randomly** dropping neurons during the training step. This forces the network to be more robust and prevent the network to build complex co-adaptations on training data.\n",
    "\n",
    "We will add dropout on the embedding layer and the LSTM hidden layer. We'll give a value of **0.5** to our dropout, which is supposed to yield the maximum regularization for big networks. However, it would be worth trying a different value for the \"input\" layer (embeddings) and the LSTM hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Adding dropout to our LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim,\n",
    "                 output_dim, dropout, padding_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, review, review_lengths):\n",
    "\n",
    "        embeddings = self.dropout(self.embedding(review))\n",
    "        \n",
    "        p_embeddings = nn.utils.rnn.pack_padded_sequence(embeddings, review_lengths)\n",
    "        p_output, (hidden, cell) = self.lstm(p_embeddings)\n",
    "        hidden = self.fc(self.dropout(hidden[-1]))\n",
    "        \n",
    "        return(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting our model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(reviews.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = 1\n",
    "dropout = 0.5\n",
    "padding_idx = reviews.vocab.stoi[reviews.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = LSTM(input_dim, embedding_dim, hidden_dim,\n",
    "                  output_dim, dropout, padding_idx)\n",
    "model_lstm = model_lstm.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the embedding layer with GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30002, 100])\n"
     ]
    }
   ],
   "source": [
    "GloVe_embeddings = reviews.vocab.vectors\n",
    "print(GloVe_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6106, -2.3774,  0.2805,  ..., -0.4891, -0.1276, -0.2461],\n",
       "        [ 1.0234, -0.3995, -0.7861,  ..., -0.1443, -0.6640, -0.7930],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.7447, -0.2493, -0.0636,  ...,  0.1555,  1.0456,  0.1147],\n",
       "        [-0.5160,  0.0312,  0.0855,  ..., -0.8593,  0.0180,  0.7858],\n",
       "        [-0.2045,  0.0965, -0.4298,  ..., -0.4046,  0.4052,  0.3617]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.embedding.weight.data.copy_(GloVe_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.7447, -0.2493, -0.0636,  ...,  0.1555,  1.0456,  0.1147],\n",
       "        [-0.5160,  0.0312,  0.0855,  ..., -0.8593,  0.0180,  0.7858],\n",
       "        [-0.2045,  0.0965, -0.4298,  ..., -0.4046,  0.4052,  0.3617]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_idx = reviews.vocab.stoi[reviews.unk_token]\n",
    "\n",
    "model_lstm.embedding.weight.data[padding_idx] = torch.zeros(embedding_dim)\n",
    "model_lstm.embedding.weight.data[unknown_idx] = torch.zeros(embedding_dim)\n",
    "model_lstm.embedding.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(model_lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0mn:16s\n",
      "\t  Training loss: 0.6625 |   Training accuracy: 60.62 %\n",
      "\tValidation loss: 0.5660 | Validation accuracy: 73.14 %\n",
      "epoch 2: 0mn:15s\n",
      "\t  Training loss: 0.6040 |   Training accuracy: 68.31 %\n",
      "\tValidation loss: 0.5217 | Validation accuracy: 75.14 %\n",
      "epoch 3: 0mn:16s\n",
      "\t  Training loss: 0.4768 |   Training accuracy: 78.14 %\n",
      "\tValidation loss: 0.3679 | Validation accuracy: 84.41 %\n",
      "epoch 4: 0mn:16s\n",
      "\t  Training loss: 0.4832 |   Training accuracy: 77.18 %\n",
      "\tValidation loss: 0.4357 | Validation accuracy: 80.10 %\n",
      "epoch 5: 0mn:16s\n",
      "\t  Training loss: 0.3338 |   Training accuracy: 86.24 %\n",
      "\tValidation loss: 0.3146 | Validation accuracy: 87.58 %\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 5\n",
    "run_lstm_model(nb_epochs, model_lstm, train_iter, valid_iter, optimiser, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Conclusion on this LSTM with dropout / GloVe emmbedings model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularistion using dropout works pretty well, certainly decreasing the accuracy on the training set, **but** definitively **increasing** the accuracy on the validation set, which is what really matters. Our model is now better on never seen reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved good progress during this notebook, but there are still some limitations, and therefore rooms from improvements. For instance, our model is not very good at giving a proper prediction on very small sentences/reviews (like, \"*This movie is not good*\"), which in some of our tries have been classified as a positive review!\n",
    "Therefore, there are still a lot that can be done. Starting with trying over (more complex and more recent) network architecture, such as:\n",
    "* Bidirectional RNN, allowing the network to build predictions from both the ***past*** (start of the sequence) and ***futur*** (end of the sequence).\n",
    "* More complex RNN architecture, i.e. LSTM (Long Short Term Memory), known to be able to better capture/learn from long sequences (which is typically the case in this dataset for movie reviews).\n",
    "* Transformers (because it is a trendy architecture ! Not sure it will work well on this problem, need to try)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
